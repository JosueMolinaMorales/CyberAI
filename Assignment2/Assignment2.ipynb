{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCS 670 - CyberAI - Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Assignment 2 Problem Description\n",
    "2. Dataset Description: CICIoT2023 - IoT Attack Classification Dataset\n",
    "   - Overview\n",
    "   - Key Contributions\n",
    "   - Challenges in IoT Security Data Production\n",
    "   - Canadian Institute for Cybersecurity (CIC)\n",
    "   - Supporting IoT Security Research \n",
    "   - Data Categories\n",
    "   - Citation\n",
    "3. 3 Classification Algorithms\n",
    "4. Experiment: Comparing Classification Algorithms  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigment 2 Problem Description\n",
    "\n",
    "Choose a dataset that is well suited for classification. You can use any dataset related to cybersecurity that\n",
    "you would like to classify. A good number of datasets can be found in the UCI machine learning data\n",
    "repository (searching keywords such like cybersecurity, security, attack and defense, intrusion\n",
    "detection, etc.) but feel free to use any dataset that you want. Make sure that you select a dataset that has\n",
    "a class variable. Then use a tool such as python, R, Weka, or RapidMiner to classify the dataset. The\n",
    "specific requirements for the assignment are as follows:\n",
    "\n",
    "* Choose a dataset that is of interest to you and is well suited for classification\n",
    "* Describe the dataset\n",
    "* Research at least 3 different classification algorithms.\n",
    "* Give an explanation of the algorithms that you are using.\n",
    "* Design an experiment using training and testing (holdout method), cross-validation, or the\n",
    "bootstrap method. Use a statistical test to validate your partition of the data.\n",
    "* Compare the results of three or more classification methods using the same experimental setup\n",
    "using one or more classification evaluation methods discussed in class. The metrics that you\n",
    "choose are up to you and can include accuracy, error rate, sensitivity, specificity, precision, recall,\n",
    "and F measure.\n",
    "* Write a report that describes your experiment and results. The report should be in either ACM or\n",
    "IEEE conference paper format and should include an introduction section that details the dataset\n",
    "and the objectives of the analysis; a methodology section that explains the approach that you are\n",
    "using to mine the dataset including the steps used to preprocess the data, the classification\n",
    "algorithms and parameters, experimental setup (e.g. holdout, cross validation, bootstrapping),\n",
    "accuracy metrics (e.g. precision, recall, f-measure, etc...); a results section that shows the results\n",
    "of your analysis and any interesting patterns that you found; and a conclusion section that\n",
    "summarizes your results, discusses the limitations of your approach, and any difficulties that you\n",
    "had with your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description: CICIoT2023 - IoT Attack Classification Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "CICIoT2023 is a real-time dataset designed to support research and development in the field of security analytics for Internet of Things (IoT) environments. The dataset comprises a wide range of IoT attack scenarios executed within a complex IoT topology consisting of 105 devices. These attacks are meticulously categorized into seven distinct classes, including Distributed Denial of Service (DDoS), Denial of Service (DoS), Reconnaissance (Recon), Web-based attacks, Brute Force attacks, Spoofing, and Mirai attacks. The primary goal of this dataset is to facilitate the development of machine learning and deep learning algorithms for the classification and detection of IoT network traffic as malicious or benign.\n",
    "\n",
    "### Key Contributions\n",
    "\n",
    "The creators of CICIoT2023 have made significant contributions to the field of IoT security:\n",
    "\n",
    "1. Realistic IoT Attack Dataset: CICIoT2023 introduces a novel and realistic IoT attack dataset. Unlike many previous datasets that rely on simulated or limited IoT device setups, this dataset leverages an extensive topology composed of actual IoT devices, mimicking real-world IoT applications.\n",
    "\n",
    "2. 33 Reproducible Attacks: The dataset includes 33 distinct attacks, carefully documented and collected as part of seven different classes. These attacks serve as valuable resources for understanding and reproducing IoT attack scenarios.\n",
    "\n",
    "3. Performance Evaluation: The dataset enables the evaluation of machine learning and deep learning algorithms for classifying and detecting IoT network traffic as malicious or benign. Researchers can assess the effectiveness of various techniques in identifying IoT attacks.\n",
    "\n",
    "### Challenges in IoT Security Data Production\n",
    "\n",
    "Producing high-quality IoT security data is a challenging endeavor, primarily due to the following factors:\n",
    "- Extensive Network Topology: Creating an IoT attack dataset that accurately reflects real-world scenarios requires an extensive network topology comprising multiple authentic IoT devices. Such setups involve substantial costs, specialized network equipment (e.g., switches, routers, network taps), and dedicated personnel for maintenance.\n",
    "\n",
    "### Canadian Institute for Cybersecurity (CIC)\n",
    "\n",
    "The Canadian Institute for Cybersecurity (CIC) is a prominent entity in the cybersecurity ecosystem, known for making substantial contributions to both industry and academia. CIC's achievements include the creation of datasets for developing new cybersecurity applications and establishing partnerships with industry stakeholders to enhance cybersecurity practices and develop innovative solutions.\n",
    "\n",
    "### Supporting IoT Security Research\n",
    "\n",
    "CIC's success has allowed the establishment of an IoT lab equipped with a dedicated network infrastructure to facilitate the development of IoT security solutions. By sharing the extensive dataset collected from this infrastructure, CIC aims to advance research in IoT security and support various initiatives addressing different aspects of IoT security.\n",
    "\n",
    "### Data Categories\n",
    "\n",
    "The dataset encompasses a wide range of IoT attacks categorized into seven classes:\n",
    "\n",
    "* DDoS Attacks: Various DDoS attack types, including ACK fragmentation, UDP flood, SlowLoris, ICMP flood, RSTFIN flood, PSHACK flood, HTTP flood, UDP fragmentation, TCP flood, SYN flood, and SynonymousIP flood.\n",
    "* Brute Force Attacks: Dictionary brute force attacks.\n",
    "* Spoofing Attacks: Arp spoofing and DNS spoofing.\n",
    "* DoS Attacks: Denial of Service attacks, including TCP flood, HTTP flood, SYN flood, and UDP flood.\n",
    "* Reconnaissance Attacks: Reconnaissance activities such as ping sweeps, OS scans, vulnerability scans, port scans, and host discovery.\n",
    "* Web-based Attacks: Web-based attack methods, including SQL injection, command injection, backdoor malware, uploading attacks, XSS (Cross-Site Scripting), and browser hijacking.\n",
    "* Mirai Attacks: Specific Mirai attacks, such as GREIP flood, Greeth flood, and UDPPlain.\n",
    "\n",
    "### Citation\n",
    "E. C. P. Neto, S. Dadkhah, R. Ferreira, A. Zohourian, R. Lu, A. A. Ghorbani. \"CICIoT2023: A real-time dataset and benchmark for large-scale attacks in IoT environment,\" Sensor (2023) â€“ (submitted to Journal of Sensors).\n",
    "\n",
    "This dataset serves as a valuable resource for researchers and practitioners aiming to enhance the security of IoT environments and develop robust intrusion detection and prevention systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Classification Algorithms\n",
    "\n",
    "The three classification algorithms that I will be using are:\n",
    "1. K-Nearest Neighbors\n",
    "2. Random Forest\n",
    "3. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Comparing Classification Algorithms\n",
    "\n",
    "In this experiment, we aim to assess and compare the performance of three different classification algorithms on a dataset. The objective is to determine which algorithm provides the best results for the given classification task.\n",
    "\n",
    "### Step 1: Data Preprocessing\n",
    "\n",
    "1. Load the dataset: The dataset is loaded into a Pandas DataFrame. It contains information about IoT attacks classified into seven categories, namely DDoS, DoS, Recon, Web-based, Brute Force, Spoofing, and Mirai.\n",
    "\n",
    "2. Split the dataset: The dataset is split into a training set and a test set. The training set will be used to train the classifiers, while the test set will be used for evaluation. A common split ratio is 70% training and 30% testing.\n",
    "\n",
    "### Step 2: Model Selection and Training\n",
    "\n",
    "For this experiment, three classification algorithms are chosen:\n",
    "\n",
    "#### Decision Tree Classifier\n",
    "\n",
    "3. Initialize the Decision Tree classifier.\n",
    "4. Train the classifier on the training data.\n",
    "\n",
    "#### K-Nearest Neighbors (KNN) Classifier\n",
    "\n",
    "5. Initialize the KNN classifier.\n",
    "6. Train the classifier on the training data.\n",
    "\n",
    "#### Support Vector Machine (SVM) Classifier\n",
    "\n",
    "7. Initialize the SVM classifier.\n",
    "8. Train the classifier on the training data.\n",
    "\n",
    "### Step 3: Model Evaluation\n",
    "\n",
    "9. Use the trained classifiers to make predictions on the test data.\n",
    "10. Evaluate the performance of each classifier using various metrics, including accuracy, precision, recall, F1-score, and the confusion matrix.\n",
    "\n",
    "### Step 4: Results and Comparison\n",
    "\n",
    "11. Compare the results of the three classifiers, considering their accuracy and other relevant metrics. Present the results in tables or visualizations.\n",
    "12. Draw conclusions about which classifier performs best on the dataset based on the evaluation metrics.\n",
    "\n",
    "Note: Hyperparameter tuning and cross-validation may be applied to optimize classifier performance.\n",
    "\n",
    "By following this experiment, we aim to make an informed decision about the most suitable classification algorithm for the given dataset and classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas, Numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the a portion of the dataset.\n",
    "**NOTE** Using only a portion of the dataset due to time and memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./datasets/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the structure of the dataframe.\n",
    "The label column is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the holdout method to split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train = dataset.sample(frac=0.7,random_state=0) # random state is a seed value, so that the same sample is selected each time\n",
    "test = dataset.drop(train.index) # drop the rows that are in the training set, so that the test set is disjoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the observations and labels for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of observations and classes\n",
    "obs = list(dataset.columns)\n",
    "# Remove the 'label' column\n",
    "obs.remove('label')\n",
    "\n",
    "# Set the target variable\n",
    "clas = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the observations from the class/target variable in both the training and testing sets.\n",
    "\n",
    "Use of ravel() "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
